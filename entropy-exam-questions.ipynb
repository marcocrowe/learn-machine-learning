{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28d2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Ensure the markcrowe package is installed\n",
    "    import data_analytics.machine_learning as machine_learning\n",
    "except ImportError:\n",
    "    print(\"markcrowe is not installed. Installing now...\")\n",
    "    %pip install markcrowe\n",
    "    import data_analytics.machine_learning as machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3c3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b29f9",
   "metadata": {},
   "source": [
    "# [Machine Learning](https://github.com/marcocrowe/learn-machine-learning \"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e4d1d",
   "metadata": {},
   "source": [
    "## Sample Question - Weather Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1d86d",
   "metadata": {},
   "source": [
    "The following dataset contains the descriptive features (`Humid`, `Cloudy`, `Windy`) which determine whether it will `Rain` (target feature). Given the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe6ac4",
   "metadata": {},
   "source": [
    "| #  | Humid | Cloudy | Windy | Rain |\n",
    "|----|-------|--------|-------|------|\n",
    "| 1  | True  | False  | True  | Yes  |\n",
    "| 2  | True  | True   | False | Yes  |\n",
    "| 3  | True  | True   | False | Yes  |\n",
    "| 4  | False | True   | True  | No   |\n",
    "| 5  | False | False  | False | No   |\n",
    "| 6  | False | False  | False | No   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7eeef8",
   "metadata": {},
   "source": [
    "### Part 1 - Discuss what is meant by Entropy. [7 Marks]\n",
    "\n",
    "Use both the definition and formula for Entropy to clarify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b441741",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "Entropy is a measure of randomness or uncertainty in a dataset. In the context of decision trees and classification problems, entropy is used to quantify the impurity of a collection of examples. A dataset with high entropy has a lot of disorder, meaning the classes are distributed randomly or evenly. On the other hand, a dataset with low entropy has less disorder, indicating that the examples belong predominantly to one class.\n",
    "\n",
    "In lay terms entropy is the 'sameness' or homogeneity in a dataset measured between 0 and 1. If the entropy is 0, it means that the dataset is perfectly homogenous, and all examples belong are the 'same'. If the entropy is 1, it means that the dataset is completely random, and the examples are not the 'same'.\n",
    "\n",
    "The formula for entropy is given by:\n",
    "\n",
    "$$ \\text{Entropy}(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i) $$\n",
    "\n",
    "where:\n",
    "- $S$ is the dataset\n",
    "- the classes of the target feature `Rain` are `Yes` and `No`\n",
    "- $i$ is the index of the class. i.e. $i=1$ represents the first class is `Yes` and $i=2$ represents the second class is `No`\n",
    "- $p_i$ is the proportion of examples in class $i$ in the dataset\n",
    "- $c$ is the number of classes in the feature/target variable of interest.\n",
    "- $\\sum_{i=1}^{c}$ is the sum of the entropy for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8584f",
   "metadata": {},
   "source": [
    "### Part 2 - Calculate the Entropy [6 Marks]\n",
    "\n",
    "Calculate the Entropy for the entire dataset above using the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03079c",
   "metadata": {},
   "source": [
    "\n",
    "$S =6$ (total number of examples)  \n",
    "\n",
    "The classes for the target feature `Rain` are `Yes` and `No`.  The number of classes $c = 2$\n",
    "\n",
    "The sum of `Yes` is 3 and the sum of `No` is 3.\n",
    "\n",
    "$P(i=1) = P( \\text{Rain} = Yes) = \\frac{3}{6} = 0.5$  \n",
    "$P(i=2) = P( \\text{Rain} = No) = \\frac{3}{6} = 0.5$\n",
    "\n",
    "$ \\text{Entropy}(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i) $\n",
    "\n",
    "since $c = 2$\n",
    " \n",
    "$ \\text{Entropy}(S) = - (p_1 \\log_2(p_1) + p_2 \\log_2(p_2)) $ \n",
    "\n",
    "Plug in the values into the formula:  \n",
    "\n",
    "$ \\text{Entropy}(S) = - (0.5 \\log_2(0.5) + 0.5 \\log_2(0.5)) $\n",
    "\n",
    "$ \\text{Entropy}(S) = - (0.5 \\times -1 + 0.5 \\times -1) $\n",
    "\n",
    "$ \\text{Entropy}(S) = - (-0.5 + -0.5) $\n",
    "\n",
    "$ \\text{Entropy}(S) = - (-1) $\n",
    "\n",
    "$ \\text{Entropy}(S) = 1 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed32c4d",
   "metadata": {},
   "source": [
    "### Alt Sample Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b54324",
   "metadata": {},
   "source": [
    "\n",
    "Calculate the Entropy for the entire dataset above using the Windy feature.\n",
    "\n",
    "$S =6$ (total number of examples)\n",
    "\n",
    "The classes for the target feature `Windy` are `True` and `False`.  The number of classes $c = 2$\n",
    "\n",
    "The sum of `True` is 2 and the sum of `False` is 4.\n",
    "\n",
    "$P(1) = P(Windy = True) = \\frac{2}{6} = 0.33$  \n",
    "$P(2) = P(Windy = False) = \\frac{4}{6} = 0.67$  \n",
    "\n",
    "$Entropy(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)$\n",
    "\n",
    "Plug in the values:\n",
    "\n",
    "$Entropy(S) = - \\left( \\frac{2}{6} \\log_2(\\frac{2}{6}) + \\frac{4}{6} \\log_2(\\frac{4}{6}) \\right) \\\\ = (0.33 \\times -1.58) + (0.67 \\times -0.58) $\n",
    "$= 0.92$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ee5ed",
   "metadata": {},
   "source": [
    "$\\cdot\\frac{\\ln\\left(.33\\right)}{\\ln\\left(2\\right)}+0.67\\cdot\\frac{\\ln\\left(.67\\right)}{\\ln\\left(2\\right)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126a9e1",
   "metadata": {},
   "source": [
    "### Part 3 - Calculate the information gain [12 Marks]\n",
    "\n",
    "Demonstrate how you would calculate the information gain for each of the above features (`Humid`, `Cloudy`, `Windy`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268ecff",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "Information gain measures the effectiveness of a feature in classifying the dataset. It indicates how much entropy is reduced when a dataset is split on a particular feature.\n",
    "\n",
    "To calculate information gain for a feature, we first calculate the weighted average of the entropies of the resulting subsets after splitting the dataset on that feature\n",
    "\n",
    "Our feature set is `Humid`, `Cloudy`, and `Windy`. We will calculate the information gain for each feature.\n",
    "\n",
    "The formula for information gain is given by:\n",
    "\n",
    "$$ Information Gain(S, A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} \\times Entropy(S_v) $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $S$ is the dataset\n",
    "- $A$ is the feature\n",
    "- $Values(A)$ is the set of possible values of feature $A$\n",
    "- $S_v$ is the subset of $S$ for which feature $A$ has value $v$\n",
    "- $|S|$ is the total number of examples in $S$\n",
    "- $|S_v|$ is the number of examples in $S_v$\n",
    "- $Entropy(S)$ is the entropy of the dataset $S$\n",
    "- $Entropy(S_v)$ is the entropy of the subset $S_v$\n",
    "- $Information Gain(S, A)$ is the information gain of feature $A$ on dataset $S$\n",
    "- $v$ is a value of feature $A$\n",
    "\n",
    "Let's calculate the information gain for each feature:\n",
    "\n",
    "1. **Humid**:\n",
    "\n",
    "- Split the dataset based on the `Humid` feature, we have two classes `True` and `False`, $c = 2$\n",
    "  - $P(1) = P(Humid = True) = \\frac{3}{6} = 0.5$  \n",
    "  - $P(2) = P(Humid = False) = \\frac{3}{6} = 0.5$  \n",
    "- Calculate the entropy of the subsets:\n",
    "  - For `Humid = True`:\n",
    "      - Number of examples = 3\n",
    "      - Number of `Yes` = 3\n",
    "      - Number of `No` = 0\n",
    "      - $Entropy(S_{Humid=True}) = 0$ (since all examples are of the same class)\n",
    "  - For `Humid = False`:\n",
    "      - Number of examples = 3\n",
    "      - Number of `Yes` = 0\n",
    "      - Number of `No` = 3\n",
    "      - $Entropy(S_{Humid=False}) = 0$ (since all examples are of the same class)\n",
    "- Calculate the information gain:\n",
    "  - $ Information Gain(S, A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} \\times Entropy(S_v) $\n",
    "  - $Information Gain(S, Humid) = Entropy(S) -  \\frac{3}{6} \\times 0 + \\frac{3}{6} \\times 0  = 1 - 0 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6fff7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Humid</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #   Humid  Cloudy  Windy Rain\n",
       "0   1   True   False   True  Yes\n",
       "1   2   True    True  False  Yes\n",
       "2   3   True    True  False  Yes\n",
       "3   4  False    True   True   No\n",
       "4   5  False   False  False   No\n",
       "5   6  False   False  False   No"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_filepath = \"exam-papers/weather-entropy-sample-question.csv\"\n",
    "target = \"Rain\"\n",
    "weather_data_frame = read_csv(weather_filepath)\n",
    "weather_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5374845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Rain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rain\n",
       "Yes    0.5\n",
       "No     0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the entropy H(D) for the target feature 'Rain'\n",
    "print(\"Probability of Rain\")\n",
    "weather_data_frame[target].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e2ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(D) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "target_entropy = entropy(\n",
    "    weather_data_frame[target].value_counts(normalize=True), base=2\n",
    ")\n",
    "print(f\"H(D) = {target_entropy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a24551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(D|Humid) = 0.0000\n",
      "H(D|Cloudy) = 0.9183\n",
      "H(D|Windy) = 1.0000\n",
      "\n",
      "IG(Humid) = H(D)- H(D|Humid) = 1.0 - 0.0000 = 1.0000\n",
      "IG(Cloudy) = H(D)- H(D|Cloudy) = 1.0 - 0.9183 = 0.0817\n",
      "IG(Windy) = H(D)- H(D|Windy) = 1.0 - 1.0000 = 0.0000\n"
     ]
    }
   ],
   "source": [
    "for feature in weather_data_frame.columns[1:-1]:  # 1 , ignores #, using -1 ignores Rain\n",
    "    feature_entropy = machine_learning.conditional_entropy(\n",
    "        weather_data_frame, feature, target\n",
    "    )\n",
    "    print(f\"H(D|{feature}) = {feature_entropy:.4f}\")\n",
    "\n",
    "print()\n",
    "for feature in weather_data_frame.columns[1:-1]:  # 1 , ignores #, using -1 ignores Rain\n",
    "    feature_entropy = machine_learning.conditional_entropy(\n",
    "        weather_data_frame, feature, target\n",
    "    )\n",
    "    print(\n",
    "        f\"IG({feature}) = H(D)- H(D|{feature}) = {target_entropy} - {feature_entropy:.4f} = {target_entropy - feature_entropy:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e110921",
   "metadata": {},
   "source": [
    "## Lab Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16769637",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame: DataFrame = read_csv(\"data.csv\")\n",
    "target = \"Annual Income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d142f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(D) = 1.2988\n"
     ]
    }
   ],
   "source": [
    "# Calculate the entropy H(D) for the target feature 'Annual Income'\n",
    "target_entropy = entropy(data_frame[target].value_counts(normalize=True), base=2)\n",
    "print(f\"H(D) = {target_entropy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ac6db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(D|Education) = 0.5000\n",
      "H(D|Marital Status) = 0.7500\n",
      "H(D|Occupation) = 0.5944\n",
      "\n",
      "IG(Education) = H(D)- H(D|Education) = 1.2987949406953987 - 0.5000 = 0.7988\n",
      "IG(Marital Status) = H(D)- H(D|Marital Status) = 1.2987949406953987 - 0.7500 = 0.5488\n",
      "IG(Occupation) = H(D)- H(D|Occupation) = 1.2987949406953987 - 0.5944 = 0.7044\n"
     ]
    }
   ],
   "source": [
    "for feature in data_frame.columns[\n",
    "    1:-1\n",
    "]:  # 1 , ignores age, using -1 ignores annual income\n",
    "    feature_entropy = machine_learning.conditional_entropy(data_frame, feature, target)\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"H(D|{feature}) = {feature_entropy:.4f}\")\n",
    "\n",
    "print()\n",
    "for feature in data_frame.columns[\n",
    "    1:-1\n",
    "]:  # 1 , ignores age, using -1 ignores annual income\n",
    "    feature_entropy = machine_learning.conditional_entropy(data_frame, feature, target)\n",
    "    print(\n",
    "        f\"IG({feature}) = H(D)- H(D|{feature}) = {target_entropy} - {feature_entropy:.4f} = {target_entropy - feature_entropy:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f6564",
   "metadata": {},
   "source": [
    "\n",
    "# Information Based Learning - ID3 Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c452d71",
   "metadata": {},
   "source": [
    "\n",
    "The dataset below describes the predictive annual income of individuals based on the descriptive features `Age`, `Education`, `Marital Status` and `Occupation`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caccebea",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1\n",
    "\n",
    "Calculate the entropy for the entire dataset. The `Annual Income` is the target feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb191d4",
   "metadata": {},
   "source": [
    "\n",
    "### Answer 1\n",
    "\n",
    "The entropy of the entire dataset is calculated as follows:\n",
    "\n",
    "$$ \\text{Entropy(\\text{Annual Income})} = - \\sum_{i=1}^{n} p_i \\log_2 p_i $$\n",
    "\n",
    "where $p_i$ is the probability of the $i$th class.\n",
    "\n",
    "The probability of each class of `Annual Income` is calculated as follows:\n",
    "\n",
    "$p(\\text{<25K}) = \\frac{2}{8} = 0.25$  \n",
    "$p(\\text{25K-50K}) = \\frac{5}{8} = 0.625$  \n",
    "$p(\\text{>50K}) = \\frac{1}{8} = 0.125$  \n",
    "\n",
    "The entropy of the entire dataset is calculated as follows:\n",
    "\n",
    "$\\text{Entropy(\\text{AI})} = - (\\text{Entropy(\\text{AI=<25K})} + \\text{Entropy(\\text{AI=25K-50K})} + \\text{Entropy(\\text{AI=>50K})})$  \n",
    "$\\text{Entropy(\\text{AI})} = - ((0.25 \\log_2 0.25) + (0.625 \\log_2 0.625) + (0.125 \\log_2 0.125))$  \n",
    "$\\text{Entropy(\\text{AI})} = - ((0.25 \\times -2) + (0.625 \\times 0.6781) + (0.125 \\times -3))$  \n",
    "$\\text{Entropy(\\text{AI})} = - (-0.5 + -0.4238 + -0.375)$  \n",
    "$\\text{Entropy(\\text{AI})} = - (-1.2988)$  \n",
    "$\\text{Entropy(\\text{AI})} = 1.2988$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124be69",
   "metadata": {},
   "source": [
    "\n",
    "| Id | Age | Education   | Marital Status | Occupation   | Annual Income |\n",
    "|----|-----|-------------|----------------|--------------|---------------|\n",
    "| 1  | 39  | bachelors   | never married  | transport    | 25K-50K       |\n",
    "| 2  | 50  | bachelors   | married        | professional | 25K-50K       |\n",
    "| 3  | 18  | high school | never married  | agriculture  | <25K          |\n",
    "| 4  | 28  | bachelors   | married        | professional | 25K-50K       |\n",
    "| 5  | 37  | high school | married        | agriculture  | 25K-50K       |\n",
    "| 6  | 24  | high school | never married  | armed forces | <25K          |\n",
    "| 7  | 52  | high school | divorced       | transport    | 25K-50K       |\n",
    "| 8  | 40  | doctorate   | married        | professional | >50K          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23ec4a",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ce610",
   "metadata": {},
   "source": [
    "\n",
    "Using this dataset construct the decision tree that would be generated by the ID3 algorithm: using entropy-based information gain. (only use the `Education` `Marital Status`, `Occupation` descriptive features)\n",
    "\n",
    "Clearly show the entropy and information gain for each feature that was generated by the ID3 algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d2d4a",
   "metadata": {},
   "source": [
    "\n",
    "### Answer 2\n",
    "\n",
    "The decision tree generated by the ID3 algorithm is as follows:\n",
    "\n",
    "1. **Root Node**: The root node is the feature with the highest information gain.  \n",
    "   - Calculate the information gain for each feature: `Education`, `Marital Status`, and `Occupation`.\n",
    "\n",
    "$$ \\text{Information Gain} = \\text{H(\\text{Annual Income})} - \\text{H(\\text{Annual Income} | \\text{Feature})} $$\n",
    "\n",
    "   - Calculate the entropy for each feature.\n",
    " - **Education**:\n",
    "   - Calculate the entropy for each class of `Education`.\n",
    "   - Calculate the information gain for `Education`.\n",
    "   - $p(\\text{bachelors}) = \\frac{3}{8} = 0.375$\n",
    "   - $p(\\text{high school}) = \\frac{4}{8} = 0.5$\n",
    "   - $p(\\text{doctorate}) = \\frac{1}{8} = 0.125$\n",
    "   - $ \\text{H(\\text{AI | Education})} = - \\sum_{i=1}^{n} p_i \\text{Entropy(\\text{AI=class})} $\n",
    "   - $ \\text{H(\\text{AI | Education})} = -(\\text{Entropy(\\text{AI=bachelors})} + \\text{Entropy(\\text{AI=high school})} + \\text{Entropy(\\text{AI=doctorate})})$\n",
    "   - $\\text{H(\\text{AI | Education})} = - (0.375 \\times log_2 0.375) + (0.5 \\times log_2 0.5) + (0.125 \\times log_2 0.125)$\n",
    "   - $\\text{H(\\text{AI | Education})} = - (0.375 \\times -1.415) + (0.5 \\times -1) + (0.125 \\times -3)$\n",
    "   - $\\text{H(\\text{AI | Education})} = - (-0.5306 - 0.5 - 0.375)$  \n",
    "   - $\\text{H(\\text{AI | Education})} = -(-1.4056) = 1.4056$  \n",
    "   - $S_{\\text{bachelors}} = 3$\n",
    "   - $S_{\\text{high school}} = 4$\n",
    "   - $S_{\\text{doctorate}} = 1$\n",
    "\n",
    "\n",
    "\n",
    "## Question 3\n",
    "\n",
    "A colleague suggests that the feature `Marital Status` should be the root of the tree. Would you agree with this? Clearly explain your reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa5a2d",
   "metadata": {},
   "source": [
    "## Question 5 Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1194c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentId</th>\n",
       "      <th>Study</th>\n",
       "      <th>AttendLectures</th>\n",
       "      <th>CompleteCA</th>\n",
       "      <th>PassMachineLearning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K00101010</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K00101020</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K00101030</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K00101040</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K00101050</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K00101060</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K00101070</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K00101080</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K00101090</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K00101100</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentId Study AttendLectures CompleteCA PassMachineLearning\n",
       "0  K00101010   Yes            Yes        Yes                 Yes\n",
       "1  K00101020    No            Yes        Yes                 Yes\n",
       "2  K00101030   Yes            Yes         No                 Yes\n",
       "3  K00101040    No            Yes         No                  No\n",
       "4  K00101050   Yes             No        Yes                 Yes\n",
       "5  K00101060    No             No         No                  No\n",
       "6  K00101070   Yes             No         No                  No\n",
       "7  K00101080    No            Yes         No                  No\n",
       "8  K00101090   Yes             No        Yes                 Yes\n",
       "9  K00101100   Yes             No         No                  No"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = read_csv(\"exam-papers/student-pass-data.csv\")\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515b4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "dtype: bool\n",
      "P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes)): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the condition for (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes)\n",
    "condition = (\n",
    "    (data_frame[\"Study\"] == \"Yes\")\n",
    "    & (data_frame[\"AttendLectures\"] == \"Yes\")\n",
    "    & (data_frame[\"CompleteCA\"] == \"Yes\")\n",
    ")\n",
    "\n",
    "print(condition)\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "filtered_df = data_frame[condition]\n",
    "\n",
    "# Calculate the total number of students who meet the criteria\n",
    "total_students_meet_criteria = len(filtered_df)\n",
    "\n",
    "# Calculate the number of students who meet the criteria and passed the machine learning module\n",
    "students_passed = filtered_df[\"PassMachineLearning\"].value_counts().get(\"Yes\", 0)\n",
    "\n",
    "# Calculate the conditional probability P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes))\n",
    "if total_students_meet_criteria > 0:\n",
    "    conditional_probability = students_passed / total_students_meet_criteria\n",
    "else:\n",
    "    conditional_probability = (\n",
    "        0  # If no students meet the criteria, the probability is set to 0\n",
    "    )\n",
    "\n",
    "# Print the conditional probability\n",
    "print(\n",
    "    f\"P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes)): {conditional_probability}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7254deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes)): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame based on the condition\n",
    "filtered_df = data_frame[condition]\n",
    "\n",
    "# Calculate the total number of students who meet the criteria\n",
    "total_students_meet_criteria = len(filtered_df)\n",
    "\n",
    "# Calculate the number of students who meet the criteria and passed the machine learning module\n",
    "students_passed = filtered_df[\"PassMachineLearning\"].value_counts().get(\"Yes\", 0)\n",
    "\n",
    "# Calculate the conditional probability P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes))\n",
    "if total_students_meet_criteria > 0:\n",
    "    conditional_probability = students_passed / total_students_meet_criteria\n",
    "else:\n",
    "    conditional_probability = (\n",
    "        0  # If no students meet the criteria, the probability is set to 0\n",
    "    )\n",
    "\n",
    "# Print the conditional probability\n",
    "print(\n",
    "    f\"P(PassMachineLearning = Yes | (Study = Yes), (AttendLectures = Yes), (CompleteCA = Yes)): {conditional_probability}\"\n",
    ")\n",
    "\n",
    "# Optional: If you want to perform statistical tests, you can use scipy.stats module\n",
    "# Example of a chi-square test for independence between 'PassMachineLearning' and 'CompleteCA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1be5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Copyright &copy; 2024 Mark Crowe <https://github.com/marcocrowe>. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
